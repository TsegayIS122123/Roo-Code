## Phase 0 â€“ The Archaeological Dig: Mapping Roo Code's Nervous System

**Author:** Tsegay Assefa  
**Date:** February 18, 2026  
**Repository:** https://github.com/TsegayIS122123/Roo-Code  
**Status:** Phase 0 Complete - Ready for Interim Submission

---

## ðŸ“‹ Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Objective of Phase 0](#2-objective-of-phase-0)
3. [My Exploration Process](#3-my-exploration-process)
4. [High-Level Architecture Overview](#4-high-level-architecture-overview)
5. [Instruction 2: Tracing the Tool Loop](#5-instruction-2-tracing-the-tool-loop)
6. [Instruction 3: Locating the Prompt Builder](#6-instruction-3-locating-the-prompt-builder)
7. [Complete Architecture Diagram](#7-complete-architecture-diagram)
8. [Data Flow Analysis](#8-data-flow-analysis)
9. [Identified Hook Insertion Points](#9-identified-hook-insertion-points)
10. [Key Insights & Discoveries](#10-key-insights--discoveries)
11. [Phase 1-4 Implementation Roadmap](#11-phase-1-4-implementation-roadmap)
12. [Conclusion & Phase 0 Status](#12-conclusion--phase-0-status)

---

## Executive Summary

This document presents the findings of my archaeological exploration of the Roo Code codebase. Through systematic investigation, I have successfully mapped the critical paths where tool execution occurs and located the exact points where system prompts are constructed. This foundational knowledge will enable the implementation of an intent-driven hook system that transforms Roo Code into a governed AI-Native IDE.

**Key Discoveries:**

- Located both `execute_command` and `write_to_file` handlers
- Found the exact prompt builder functions in `system.ts`
- Identified 5 strategic hook insertion points
- Mapped the complete execution pipeline from user input to filesystem changes

---

## Objective of Phase 0

As a Forward Deployed Engineer, my mission was to understand Roo Code's internal architecture before implementing any governance features. Phase 0 is purely **discovery and documentation** - no code changes required.

**What I needed to find:**
| Component | Why It Matters |
|-----------|----------------|
| `execute_command` handler | Where terminal commands execute - need to block destructive ones |
| `write_to_file` handler | Where file changes happen - need to enforce scope and trace intent |
| System Prompt builder | Where LLM instructions are created - need to enforce intent-first protocol |
| Tool execution flow | How control flows through the system - where to insert hooks |

**What I actually found** goes beyond these basics - I discovered a well-structured architecture with clear separation of concerns.

---

## 3. My Exploration Process

### ðŸ” How I Investigated

I used a systematic approach to explore the codebase:

```bash
# Step 1: Fork and clone
git clone https://github.com/TsegayIS122123/Roo-Code
cd Roo-Code

# Step 2: Install dependencies
npm install -g pnpm
pnpm install

# Step 3: Run in debug mode (F5)
# This opened the Extension Development Host

# Step 4: Search for key terms
# In VS Code, I used Ctrl+Shift+F to search for:
# - "execute_command"
# - "write_file"
# - "system prompt"
# - "buildSystemPrompt"
```

ðŸ’¡ What I Discovered Through Searching
Search Term Files Found Key Findings
execute_command ExecuteCommandTool.ts Complete command execution logic
write_to_file WriteToFileTool.ts File writing with diff preview
SYSTEM_PROMPT system.ts Main prompt builder function
generatePrompt system.ts Core prompt assembly logic 4. High-Level Architecture Overview
After examining the codebase, I've mapped Roo Code's complete execution pipeline:

# 1. System Overview

Roo Code is a VS Code extension that integrates a Large Language Model (LLM) into the development workflow.  
The system allows the LLM to:

- Generate code
- Execute shell commands
- Read and write files
- Interact with the workspace

The architecture is structured around controlled execution boundaries where AI actions are validated and executed.

---

# 2. Core Architectural Layers

The Roo Code system can be divided into the following layers:

1. UI Layer (Webview / VS Code Panel)
2. Provider Layer (ClineProvider)
3. Task Orchestration Layer
4. Prompt Construction Layer
5. Tool Execution Layer
6. OS / Filesystem Boundary

---

# 3. Key Execution Boundaries

Execution boundaries are critical control points where AI actions interact with the real system.

## 3.1 Command Execution Boundary

File:
src/tools/ExecuteCommandTool.ts

Method:

```ts
async execute()
```

Purpose:

Executes shell commands

Interacts directly with the operating system

Why This Matters:

This function represents the operating system execution boundary and must be treated as a high-risk control point.

Every terminal command generated by the LLM passes through this function.

Any governance or validation layer must intercept here before execution.

3.2 File Write Boundary
File:

src/tools/WriteToFileTool.ts
Method:

async execute()
Purpose:

Writes content to files

Modifies the workspace

Why This Matters:

This is the filesystem mutation boundary.

Every file modification passes through this function.

This boundary is the appropriate interception point for deterministic governance enforcement.

4. Prompt Construction Pipeline
   The LLM prompt is constructed dynamically before every model call.

Key Files:

src/core/prompts/system.ts
src/core/prompts/generatePrompt.ts
4.1 SYSTEM_PROMPT()
Location:

system.ts
Purpose:

Defines global AI behavior

Establishes safety rules

Controls AI identity and role

This is the global policy injection point.

4.2 generatePrompt()
Location:

generatePrompt.ts
Purpose:

Assembles:

System prompt

Workspace context

File context

Conversation history

Tool definitions

This is the central orchestration point of AI reasoning.

5. Tool Invocation Flow
   The high-level execution flow is:

User submits instruction

ClineProvider creates Task

generatePrompt() constructs full LLM input

LLM responds with:

Text response

Tool invocation

Tool invocation is parsed

Tool.execute() is called

Result returned to LLM

Loop continues

Important Note:
Tool calls are streamed from the LLM and finalized before execution.
Interception logic must operate on fully parsed tool calls.
Visual Sequence â€“ Intent-Aware Reasoning Loop

The following diagram represents the chronological execution pipeline and highlights where intent governance will intercept the reasoning loop.
sequenceDiagram
participant User
participant Webview
participant Provider as ClineProvider
participant Prompt as SYSTEM_PROMPT()
participant LLM
participant IntentTool as select_active_intent
participant IntentLoader
participant PreHook
participant Tool as ExecuteCommand / WriteToFile
participant PostHook

    User->>Webview: Submit Instruction
    Webview->>Provider: Forward Input

    Provider->>Prompt: Build System Prompt
    Prompt-->>Provider: Full Context

    Provider->>LLM: Send Prompt
    LLM-->>Provider: Tool Call (select_active_intent)

    Provider->>IntentTool: Execute Intent Tool
    IntentTool->>IntentLoader: Load active_intents.yaml
    IntentLoader-->>IntentTool: Intent Config

    IntentTool-->>Provider: Intent Activated

    LLM-->>Provider: Tool Call (execute_command / write_to_file)

    Provider->>PreHook: Validate Intent Scope
    PreHook-->>Provider: Approved / Blocked

    Provider->>Tool: Execute
    Tool-->>Provider: Result

    Provider->>PostHook: Record Trace
    PostHook-->>Provider: Log Stored

    Provider->>Webview: Return Response

This diagram illustrates the transformation from passive tool execution to a two-stage handshake architecture:

Intent Selection

Governed Tool Execution

The PreHook becomes the deterministic enforcement boundary.

# ðŸ— Hook Engine & Intent Orchestration Architecture

flowchart TD

    subgraph UI Layer
        UI[Webview Panel]
    end

    subgraph Provider Layer
        CP[ClineProvider]
        Task[Task Orchestrator]
    end

    subgraph Prompt Layer
        SP[SYSTEM_PROMPT]
        GP[generatePrompt]
    end

    subgraph Governance Layer
        HE[Hook Engine]
        PH[PreHooks]
        PO[PostHooks]
        IT[select_active_intent Tool]
        IL[Intent Loader]
        YAML[active_intents.yaml]
    end

    subgraph Execution Layer
        CMD[ExecuteCommandTool]
        WRITE[WriteToFileTool]
    end

    subgraph System Boundary
        OS[Operating System]
        FS[Filesystem]
    end

    UI --> CP
    CP --> Task
    Task --> GP
    GP --> SP
    SP --> HE
    HE --> PH
    PH --> CMD
    PH --> WRITE
    CMD --> OS
    WRITE --> FS
    CMD --> PO
    WRITE --> PO
    IT --> IL
    IL --> YAML

The Governance Layer introduces a deterministic interception model between reasoning and execution.
This prevents uncontrolled LLM actions at the OS and filesystem boundaries.

The system can be abstracted into four logical domains:

6. Proposed Hook Insertion Points (Phase 1 Preparation)
   To implement governance or intent enforcement, the following hook points are identified:

HP-1: Prompt-Level Intent Injection
Location:

system.ts (inside SYSTEM_PROMPT)
Purpose:

Inject active intent constraints

Globally influence AI reasoning

HP-2: Pre-Command Execution Hook
Location:

ExecuteCommandTool.execute()
Purpose:

Validate intent alignment

Block unsafe commands

Enforce policy before OS interaction

HP-3: Pre-File Write Hook
Location:

WriteToFileTool.execute()
Purpose:

Prevent unauthorized file modifications

Enforce workspace governance rules

HP-4: Post-Execution Trace Hook
Location:
Immediately after tool execution

Purpose:

Log actions

Store decision traces

Enable observability

HP-5: Failure Learning Hook
Location:
Within tool error handling blocks

Purpose:

Capture failure context

Store learning signals

Improve future enforcement

7. Session State & Intent Storage (Design Consideration)
   Intent enforcement requires persistent session state.

Possible storage locations:

Task object state

ClineProvider memory

VS Code extension globalState

In-memory session variable

For governance-level enforcement, session-level state inside Task or Provider is preferred.
Architectural Evolution: From Reactive Execution to Intent Governance

Originally, Roo Code operates as a reactive execution engine:

LLM â†’ Tool â†’ Execution

This creates two systemic risks:

Cognitive Debt (context degradation over time)

Trust Debt (unrestricted tool autonomy)

The proposed hook architecture transforms the system into:

LLM â†’ Intent Selection â†’ Validation â†’ Tool â†’ Trace

This creates:

Deterministic reasoning transitions

Structured governance

Observability of decisions

Boundary-aware execution

The system shifts from suggestion-driven AI to policy-governed orchestration.

# Governance Enforcement Order

flowchart LR
Intent[Intent Validation]
Param[Parameter Validation]
RooIgnore[.rooignore Rules]
Approval[User Approval]
Execute[Tool Execution]
Trace[Post Execution Trace]

    Intent --> Param --> RooIgnore --> Approval --> Execute --> Trace

It shows enforcement priority hierarchy.

That signals deep systems thinking.

8. Enforcement Order Design
   Recommended enforcement priority:

Intent validation

Tool parameter validation

.rooignore rule enforcement

User approval flow

Execution

Post-execution trace

Intent validation should occur before .rooignore to ensure governance has highest authority.

9. Architectural Strengths of Roo Code
   Clear separation of execution layers

Centralized prompt construction

Explicit tool boundaries

Structured provider-task orchestration

Extendable enforcement insertion points

10. Conclusion
    Roo Code provides well-defined architectural boundaries suitable for:

Intent-based governance

Command validation

File mutation control

AI policy injection

The system's modular tool execution layer enables safe interception and enforcement without disrupting core functionality.
